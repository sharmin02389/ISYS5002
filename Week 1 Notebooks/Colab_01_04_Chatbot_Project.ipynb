{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmin02389/ISYS5002/blob/main/Week%201%20Notebooks/Colab_01_04_Chatbot_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygi6y4JbOyRb"
      },
      "source": [
        "## Welcome to Your Chatbot Adventure!\n",
        "\n",
        "This week, we're diving into a fun project where you'll build and customise a **simple AI Chatbot** using only `print()` statements. Although our chatbot isnâ€™t powered by real artificial intelligence yet, you'll learn how to create a friendly, engaging conversation using basic Python commands.\n",
        "\n",
        "Our goal is not just to complete the script, but to spark your creativity! Think of this as your first step towards creating digital characters that respond in unique ways. As you modify the chatbot, try to give it personalityâ€”maybe even a dash of humour. Use AI to help guide your changes if you ever get stuck, but remember: the focus is on understanding how the `print()` function works and making your chatbot truly your own.\n",
        "\n",
        "Ready to chat with your code? Letâ€™s get started!\n",
        "\n",
        "## Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "kF2H9eUJOyRd",
        "outputId": "8927e2a4-3dfc-491c-82b3-11c8ffb91646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to CodeBuddy!\n",
            "I'm a simple chatbot.Let's chat!\n",
            "\n",
            "You: Hello!\n",
            "Bot: Hi there! How can I help you today?\n",
            "\n",
            "You: What's your name?\n",
            "Bot: I'm CodeBuddy, but you can call me ChatBot!\n",
            "\n",
            "You: What's your favourite programming language?\n",
            "Bot: python!\n",
            "\n",
            "You: Bye!\n",
            "Bot: Goodbye! Have a great day!\n"
          ]
        }
      ],
      "source": [
        "print(\"Welcome to CodeBuddy!\")\n",
        "print(\"I'm a simple chatbot.Let's chat!\")\n",
        "\n",
        "print(\"\\nYou: Hello!\")\n",
        "print(\"Bot: Hi there! How can I help you today?\")\n",
        "\n",
        "print(\"\\nYou: What's your name?\")\n",
        "print(\"Bot: I'm CodeBuddy, but you can call me ChatBot!\")\n",
        "\n",
        "print(\"\\nYou: What's your favourite programming language?\")\n",
        "print(\"Bot: python!\")\n",
        "\n",
        "print(\"\\nYou: Bye!\")\n",
        "print(\"Bot: Goodbye! Have a great day!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YErkm12OyRd"
      },
      "source": [
        "## Modification Tasks for Students\n",
        "\n",
        "Now itâ€™s your turn to customise the conversation. Here are some challenges to make your chatbot more interesting and personalised:\n",
        "\n",
        "1. **Change the Chatbotâ€™s Name:**  \n",
        "   Replace `\"ChatBot\"` with a new, creative name (for example, `\"CodeBuddy\"`).\n",
        "\n",
        "2. **Add Some Personality:**  \n",
        "   Make the responses friendlier or even a bit humorous. For instance, change `\"I'm just a chatbot.\"` to something like `\"I'm ChatBot 2.0, your clever virtual companion!\"`\n",
        "\n",
        "3. **Expand the Conversation:**  \n",
        "   Include new responses. How about adding a question like, `\"What's your favourite programming language?\"` along with a quirky answer.\n",
        "\n",
        "4. **Enhance the Formatting:**  \n",
        "   Use `\\n` for better readability or adjust the layout of the responses to make them more engaging.\n",
        "\n",
        "Let your creativity shineâ€”remember, the aim is to understand how Python's `print()` command works while making your chatbot uniquely yours. Enjoy the process and happy coding!\n",
        "\n",
        "\n",
        "\n",
        "## Extension Activity (Optional)\n",
        "\n",
        "Congratulations on finishing the official exercises! Now, if you're feeling curious or want a glimpse of whatâ€™s coming up, check out this **optional extension**. This section explores two more advanced chatbot approaches. **Remember: these are completely optionalâ€”if it feels overwhelming, itâ€™s perfectly fine to skip this part.**\n",
        "\n",
        "Right now, we are just using `print()`, but letâ€™s see how chatbots evolve...\n",
        "\n",
        "Initially, we tried a *Rule-Based Chatbot*. These chatbots interact by following a set of rules, but as the number of rules grows, managing all the special cases becomes a challenge. (Soon, youâ€™ll learn how to make your chatbot interactive using `if-elif` and `while` loops.)\n",
        "\n",
        "Modern chatbots, however, are based on large language models. Later, weâ€™ll see how modern chatbots work by using AI models like GPT. Donâ€™t worry if this looks complexâ€”by the end of this course, youâ€™ll understand the core building blocks.\n",
        "\n",
        "**Extension Task:** Ask an AI to generate a chatbot script. Consider: \"How does AI structure a chatbot differently from our simple `print()` approach?\"  \n",
        "> **Note:** This task is trickier and might require some well-thought-out prompts for the AI. Later in the semester, weâ€™ll learn how to ask AI the right questions. For now, just experiment and see what output you get. Does the AI-generated code run without errors? To help you out, some sample AI outputs are provided below if you have trouble crafting your prompt.\n",
        "\n",
        "\n",
        "\n",
        "### AI-Generated Rule-Based Chatbot\n",
        "\n",
        "Hereâ€™s an **AI-generated chatbot script** that takes **user input**, uses **if-elif conditions**, and provides **dynamic responses**â€”a step up from the `print()`-only version. Run the code below and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "ts5KKyM7OyRe",
        "outputId": "9de567b4-c5b1-4bcc-e7a2-260dfef0da7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to ChatBot 2.0! Type 'bye' to exit.\n",
            "\n",
            "You: hello\n",
            "Bot: Hi there! How can I help you today?\n",
            "\n",
            "You: whats your name?\n",
            "Bot: Sorry, I donâ€™t understand. Can you ask something else?\n",
            "\n",
            "You: what's your name?\n",
            "Bot: I'm ChatBot 2.0, your AI-powered assistant!\n",
            "\n",
            "You: what can you do?\n",
            "Bot: I can answer simple questions and chat with you.\n",
            "\n",
            "You: tell me a joke\n",
            "Bot: Why don't programmers like nature? Too many bugs! ðŸ˜‚\n",
            "\n",
            "You: bye\n",
            "Bot: Goodbye! Have a great day!\n"
          ]
        }
      ],
      "source": [
        "# Simple Rule-Based Chatbot\n",
        "print(\"Welcome to ChatBot 2.0! Type 'bye' to exit.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nYou: \").lower()\n",
        "\n",
        "    if user_input == \"hello\":\n",
        "        print(\"Bot: Hi there! How can I help you today?\")\n",
        "    elif user_input == \"what's your name?\":\n",
        "        print(\"Bot: I'm ChatBot 2.0, your AI-powered assistant!\")\n",
        "    elif user_input == \"what can you do?\":\n",
        "        print(\"Bot: I can answer simple questions and chat with you.\")\n",
        "    elif user_input == \"tell me a joke\":\n",
        "        print(\"Bot: Why don't programmers like nature? Too many bugs! ðŸ˜‚\")\n",
        "    elif user_input == \"bye\":\n",
        "        print(\"Bot: Goodbye! Have a great day!\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Bot: Sorry, I donâ€™t understand. Can you ask something else?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWF7j172OyRe"
      },
      "source": [
        "## Key Differences from the `print()`-only Approach\n",
        "\n",
        "This might not make complete sense in week 1, but in a few weeks you can revisit this section and see if the differences become clearer:\n",
        "\n",
        "- **Uses `input()`** â€“ The user **interacts dynamically** rather than just reading hardcoded responses.\n",
        "- **Uses a `while` loop** â€“ The program keeps running until the user types `'bye'`.\n",
        "- **Handles conditions with `if-elif` statements** â€“ It provides **different responses** based on the input.\n",
        "- **Normalises input (`lower()`)** â€“ Ensures the interaction is case-insensitive (e.g., `\"Hello\"` is the same as `\"hello\"`).\n",
        "- **Includes a fallback response** â€“ If the user input isnâ€™t recognised, the bot gives a default response.\n",
        "\n",
        "\n",
        "\n",
        "### Basic LLM Chatbot (OpenAI GPT API)\n",
        "\n",
        "First, install the OpenAI package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "Lx_M7DxhOyRe",
        "outputId": "37480093-22e7-4cf4-d96e-09aeaba649cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSQ6_bUaOyRe"
      },
      "source": [
        "> **Note:** A **package** in Python is a collection of **pre-written code** that you can use to add extra functionality to your programs without having to write everything from scratch. Think of it like an **app on your phone**â€”you install it when you need a specific feature. Later in the semester, we'll learn how to install and use packages, but for now, just know that they help programmers **save time and avoid reinventing the wheel** by providing ready-made tools for tasks like data analysis, web development, and automation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "dg9dJP2AOyRe"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Set up OpenAI API key (Replace 'your-api-key' with an actual API key)\n",
        "openai.api_key = \"your-api-key\"\n",
        "\n",
        "def chat_with_ai():\n",
        "    print(\"AI ChatBot is ready! Type 'bye' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        if user_input.lower() == \"bye\":\n",
        "            print(\"Bot: Goodbye! Have a great day!\")\n",
        "            break\n",
        "\n",
        "        # Send user input to OpenAI's API and get a response\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": user_input}]\n",
        "        )\n",
        "\n",
        "        # Print the AI's response\n",
        "        print(\"Bot:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "# Run the chatbot\n",
        "chat_with_ai()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzDwlUqyOyRe"
      },
      "source": [
        "### Minimal LLM Chatbot Using `transformers` (Local Model)\n",
        "\n",
        "If youâ€™d rather use a **local** language model without API keys, you can use the `transformers` library (e.g., models like `mistral`, `llama`, or `phi` from Hugging Face). This approach requires a bit more skill and installation of the library. Hereâ€™s the simplest version:\n",
        "\n",
        "First, install the transformer package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "honrFt8BOyRe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUxMYTsgOyRf"
      },
      "source": [
        "Once thatâ€™s done, try the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "b7bczpZZOyRf"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a small conversational model (you can change the model if needed)\n",
        "chatbot = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "def chat():\n",
        "    print(\"Local AI ChatBot is ready! Type 'bye' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        if user_input.lower() == \"bye\":\n",
        "            print(\"Bot: Goodbye! Have a great day!\")\n",
        "            break\n",
        "\n",
        "        response = chatbot(user_input, max_length=100, do_sample=True)\n",
        "        print(\"Bot:\", response[0][\"generated_text\"])\n",
        "\n",
        "# Run the chatbot\n",
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9jVFD0ZOyRf"
      },
      "source": [
        "## Key Features of These LLM Chatbots\n",
        "\n",
        "- **No Memory** â€“ Each response is generated based solely on the current user input.\n",
        "- **Minimal Complexity** â€“ No advanced prompt engineering, embeddings, or conversation history.\n",
        "- **Uses an API or Local Model** â€“ Works with OpenAI's API or runs locally using Hugging Face models.\n",
        "- **Uses `input()`** â€“ The interaction is dynamic rather than hardcoded.\n",
        "- **Uses a `while` loop** â€“ The program continues until the user types `'bye'`.\n",
        "- **Normalises input (`lower()`)** â€“ Ensures that `\"Hello\"` and `\"hello\"` are treated the same.\n",
        "\n",
        "\n",
        "\n",
        "Happy coding, and rememberâ€”this extension is just a peek at the future. Focus on mastering the basics now, and if you're feeling adventurous, explore these extra challenges to see where your coding journey can take you!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}